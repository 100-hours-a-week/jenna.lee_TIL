1️⃣ ResNet50 & VGG16 모델 학습 및 비교
사전 훈련된 ResNet50과 VGG16을 활용하여 CIFAR-10 분류 모델을 학습
Feature Extractor → Fine-Tuning 단계를 거쳐 최적의 성능 도출
두 모델의 학습 속도 및 정확도를 비교

2️⃣ GridSearch & RandomSearch를 활용한 하이퍼파라미터 튜닝
가상 데이터셋(Sklearn make_classification)을 생성하여 RandomForestClassifier 학습
GridSearch와 RandomSearch를 사용하여 최적의 하이퍼파라미터 탐색
두 방식의 성능 및 실행 속도를 비교

✅ 배운 점
Transfer Learning을 적용할 때 Feature Extractor → Fine-Tuning 순서가 중요함
ResNet50은 빠르고 정확도가 높아 실무에서도 유용할 가능성이 높음
VGG16은 안정적인 학습이 가능하지만 속도가 상대적으로 느림
하이퍼파라미터 튜닝에서는 GridSearch보다는 RandomSearch가 더 효율적인 경우가 많음

느낌점
과제를 하면서 시간도 오래걸리고...그리고 ResNet50과 VGG16의 성능을 비교하고, GridSearch 및 RandomSearch를 활용하여 최적의 하이퍼파라미터를 탐색하는 과정을 학습하였습니다.
특히, ResNet50의 성능이 VGG16보다 뛰어나며, GridSearch보다 RandomSearch가 실무에서 더 유용할 가능성이 높다는 점을 확인할 수 있었습니다.
